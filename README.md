ğŸŒ AI Emulator for Weather & Earth System Modeling

This project presents a deep learningâ€“based AI emulator for weather prediction and extreme event detection using historical and live meteorological data.
The system trains and compares multiple neural network architectures, evaluates them using standard research metrics, and deploys them for real-time inference.

ğŸš€ Project Motivation

Traditional weather prediction models are computationally expensive and complex.
This project explores how AI emulators can approximate weather parameterization using historical climate data while remaining efficient and deployable.

Unlike simple prediction apps, this project includes:

Multiple deep learning models

Proper train/validation/test evaluation

Quantitative comparison using metrics

Live data inference

This adds a strong research component, suitable for academic publication.

ğŸ“Š Dataset
Source

NASA POWER (Prediction of Worldwide Energy Resources)

Hourly historical weather data

Locations Used

Bangalore

Mumbai

Chennai

Delhi

Input Features

Rainfall

Temperature

Wind speed

Relative humidity

Surface pressure

Output Targets

Regression (Next hour):

Temperature

Rainfall

Wind speed

Classification (Extreme events):

Cloudburst

Thunderstorm

Heatwave

Coldwave

Cyclone-like

ğŸ§  Dataset Engineering

A sliding window approach is used:

Input: past 6 hours Ã— 5 features

Output: next-hour predictions

This converts raw weather data into a time-series supervised learning problem.

Implemented in:

datasets/window_dataset.py

ğŸ—ï¸ Models Implemented

All models use the same dataset, inputs, targets, and normalization for fair comparison.

Model	Description
MLP	Baseline model (no temporal awareness)
LSTM	Captures long-term temporal dependencies
GRU	Efficient alternative to LSTM
CNN-LSTM	Combines local feature extraction + temporal modeling
Transformer	Attention-based long-range dependency modeling

Each model predicts:

Continuous weather variables (regression)

Extreme event probabilities (classification)

âš™ï¸ Training Setup

Loss Function:

Regression â†’ MSE Loss

Classification â†’ BCEWithLogits Loss

Optimizer: Adam

Same hyperparameters across models

Models saved as .pt checkpoints

Training scripts are located in:

train/

ğŸ“ˆ Evaluation Methodology
Data Split

Training: 70%

Validation: 15%

Testing: 15% (unseen during training)

Metrics Used

Classification:

Accuracy

Precision

Recall

F1-score

Regression:

Mean Absolute Error (MAE)

Evaluation is performed only on the test set, ensuring unbiased results.

Evaluation script:

eval/evaluate_all_models.py

ğŸŒ Live Inference (Deployment)

The project supports real-time weather inference using live data.

Live Pipeline

Fetch last 6 hours of weather data (Open-Meteo API)

Normalize using training statistics

Run inference using trained models

Output:

Next-hour weather predictions

Extreme event probabilities

Live inference code:

live_inference/


Run:

python -m live_inference.run_live

ğŸ”„ Multi-Model Live Comparison

A comparison module allows the same live input to be passed into all trained models, enabling side-by-side comparison of predictions.

This demonstrates:

Model stability

Sensitivity to real-world data

Differences in temporal reasoning

Run:

python -m live_inference.compare_models

ğŸ§ª Key Results

Temporal models (CNN-LSTM, GRU, Transformer) outperform MLP

CNN-LSTM achieves strong balance between accuracy and stability

Transformer shows potential but requires higher computational resources

Live inference demonstrates deployability of AI emulators

ğŸ“‚ Project Structure
ai_emulator/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ window_dataset.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ mlp.py
â”‚   â”œâ”€â”€ lstm.py
â”‚   â”œâ”€â”€ gru.py
â”‚   â”œâ”€â”€ cnn_lstm.py
â”‚   â””â”€â”€ transformer.py
â”‚
â”œâ”€â”€ train/
â”‚   â””â”€â”€ training scripts
â”‚
â”œâ”€â”€ eval/
â”‚   â””â”€â”€ evaluate_all_models.py
â”‚
â”œâ”€â”€ live_inference/
â”‚   â”œâ”€â”€ run_live.py
â”‚   â”œâ”€â”€ compare_models.py
â”‚   â”œâ”€â”€ live_fetch.py
â”‚   â””â”€â”€ normalize.py
â”‚
â””â”€â”€ README.md

ğŸ“ Conclusion

This project demonstrates how AI emulators can effectively model weather dynamics by learning from historical data.
By combining rigorous evaluation with live deployment, the system bridges the gap between research and real-world application.
